<article>
	<preamble>acl2012.pdf</preamble>
	<titre>Finding Salient Dates for Building Thematic Timelines</titre>
	<auteurs>
		<auteur>
			<nom>Rémy Kessler</nom>
			<mail>kessler@limsi.fr</mail>
			<affiliation></affiliation>
		</auteur>
	</auteurs>
	<abstract>  We present an approach for detecting salient (important) dates in texts in order to automatically build event timelines from a search query ( e.g. the name of an event or person, etc.). This work was carried out on a corpus of newswire texts in English provided by the Agence France Presse (AFP). In order to extract salient dates that warrant inclusion in an event timeline, we ﬁrst recognize and normalize temporal expressions in texts and then use a machine-learning approach to extract salient dates that relate to a particular topic. We focused only on extracting the dates and not the events to which they are related. </abstract>
	<introduction> Our aim here was to build thematic timelines fora general domain topic deﬁned by a user query.This task, which involves the extraction of importantevents, is related to the tasks of Retrospective EventDetection (Yang et al., 1998), or New Event Detection, as deﬁned for example in Topic Detection andTracking (TDT) campaigns (Allan, 2002).The majority of systems designed to tackle thistask make use of textual information in a bag-ofwords manner. They use little temporal information, generally only using document metadata, suchas the document creation time (DCT). The few systems that do make use of temporal information (suchas the now discontinued Google timeline), only extract absolute, full dates (that feature a day, monthand year). In our corpus, described in Section 3.1,we found that only 7% of extracted temporal expressions are absolute dates.We distinguish our work from that of previous researchers in that we have focused primarily on extracted temporal information as opposed to othertextual content. We show that using linguistic temporal processing helps extract important events intexts. Our system extracts a maximum of temporalinformation and uses only this information to detectsalient dates for the construction of event timelines.Other types of content are used for initial thematicdocument retrieval. Output is a list of dates, rankedfrom most important to least important with respectto the given topic. Each date is presented with a setof relevant sentences.We can see this work as a new, easily evaluabletask of “date extraction”, which is an important component of timeline summarization.In what follows, we ﬁrst review some of the related work in Section 2. Section 3 presents the resources used and gives an overview of the system.The system used for temporal analysis is describedin Section 4, and the strategy used for indexing andﬁnding salient dates, as well as the results obtained,are given in Section 51. </introduction>
	<discussion> Chronologies hand-written by journalists are a veryuseful resources for evaluation of our system, as theyare completely dissociated from our research and arean exact representation of the output we aim to obtain. However, assembling such a chronology is avery subjective task, and no clear method for evaluation agreement between two journalists seems immediately apparent. Only experts can build suchchronologies, and calculating this agreement wouldrequire at least two experts from each domain, whichare hard to come by. One may then consider our system as a useful tool for building a chronology moreobjectively.To illustrate this point, we chose four speciﬁc topics6and showed one of our runs on each topic to anAFP expert for these subjects. We asked him to assess the ﬁrst 30 dates of these runs.6Namely, “Arab revolt timeline for Morocco” ,“Kyrgyzstan unrest timeline” ,“Lebanon’s new government: a timeline” ,“Libya timeline” .Topic APC APEMorocco 0.5847 0.5718Kyrgyzstan 0.6125 0.9989Libya 0.7856 1Lebanon 0.4673 0.7652Table 4: Average precision results for manual evaluationon 4 topics, against the original chronologies ( APC), andthe expert assessment ( APE).Table 4 presents results for this evaluation, comparing average precision values obtained 1) againstthe original, manual chronologies ( APC), and 2)against the expert assessment ( APE). These valuesshow that, for 3 runs out of 4, many dates returnedby the system are considered as valid by the expert,even if not presented in the original chronology.Even if this experiment is not strong enough tolead to a formal conclusion ( post-hoc evaluationwith only 4 topics and a single assessor), this tendsto show that our system produces usable outputs andthat our system can be of help to journalists by providing them with chronologies that are as useful andobjective as possible. </discussion>
	<conclusion> Conclusion </conclusion>
	<biblio>  </biblio>
</article>
