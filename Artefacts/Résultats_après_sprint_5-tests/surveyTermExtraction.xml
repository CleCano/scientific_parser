<article>
	<preamble>surveyTermExtraction.pdf</preamble>
	<titre>AUTOMATIC TERM DETECTION: A REVIEW OF CURRENT SYSTEMS</titre>
	<auteurs>
	</auteurs>
	<abstract>  In this paper we account for the main  characteristics and performance of a  number of recently developed term extraction systems. The analysed tools  represent the main strategies followed by  researchers in this area. All systems  are analysed and compared against a set of technically relevant characteristics.  </abstract>
	<introduction> In the late 80s there was an acute need , from different disciplines and goals, to automatically extract terminological units from specialised texts. In the 90s large computerised textual corpora have been constructed resulting in the first programs for terminology extraction1 (henceforth TE) which have showed encouraging results. Throughout the current decade computa tional linguists, applied linguists, translators, interpreters, scientific journalists and computer engineers have been interested in automatically isolating terminology from texts. There are many goals that have led these different profe ssional groups to design software tools so as to directly extract terminology from texts: building of glossaries, vocabularies and terminological dictionaries; text indexing; automatic translation; building of                                                            * In Bourigault, D.; Jacquemin, C.; L’Homme, M-C. (2001) Recent Advances in Computational Terminology , 53-88. 1 In order to give a broa der view of TE we use both extractor  and detector  to refer to the same notion. However, we are aware of the fact that some schol ars attribute different meanings to these words. 2 Aut omatic Term Detection: a Review of C urrent  Systems knowledge databases; construction of hype rtext systems; construction of expert systems and corpus analysis.  From the appearance of TERMINO (the first broadly known term detector) in 1990 until today a number of projects to design different types of automatic terminology detectors have been carried out to assist terminological work. However, despite the large number of studies in progress, the automatisation of the terminological extraction phase is still fraught with problems. The main problems encountered by term extractors are: (1) identification of complex terms, that is, determining where a terminological phrase begins and ends; (2) recognition of complex terms, that is, deciding whether a discursive unit constitutes a terminological phrase or a free unit; (3) identification of the terminological nature of a lexical unit, that is, knowing whether in a specialised text a lexical unit has a terminological na ture or belongs to general language and (4) appropriateness of a terminological unit to a given vocabulary (this has scarcely been addressed from the point of view of automatization).  Systems for TE are based on three types of knowledge: (a) linguistic; (b) statistical; (c) hybrid (statistical and linguistic). Hence, there are different approaches to automatic term detecti on. All systems analyse a corpus of specialised texts in electronic form and extract lists of word chunks (i.e. candidate terms) that are to be confirmed by the terminologist. To make the terminologist’s task easier the candidate term is provided with its context and, when available, with any other furt her information (freque ncy, relationship between terms, etc.) Two relevant aspects regarding the nature of terms are termhood and unithood2; TE systems may be designed based on only one of these two aspects. Some practical experiments following each scheme for ranking a set terms extracted from Japanese texts are presented in (Nakagawa & Mori, 1998). They show that results in precision and recall are very close but the set of terms extracted are a somewhat different. This is still a research issue. Alongside term detection we find the task of automatic document indexing (i.e. information retrieval, IR). This applied field of natural language processing (NLP) techniques has an interesting common point with automatic term detection, that is, word chunks that index a given document are often terminological units. This same goal explains why many extraction systems are rooted on IR as well as on the analys is of a specific IR system with no application whatsoever to TE.                                                             </introduction>
	<discussion>  </discussion>
	<conclusion> Conclusions </conclusion>
	<biblio>  </biblio>
</article>
