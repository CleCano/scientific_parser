<article>
	<preamble>BLESS.pdf</preamble>
	<titre>How we BLESSed distributional semantic evaluation</titre>
	<auteurs>
		<auteur>
			<nom>Marco Baroni</nom>
			<mail>marco.baroni@unitn.it</mail>
			<affiliation></affiliation>
		</auteur>
	</auteurs>
	<abstract>  We introduce BLESS, a data set speciﬁcally designed for the evaluation of distributional semantic models. BLESS contains a set of tuples instantiating different, explicitly typed semantic relations, plus a number of controlled random tuples. It is thus possible to assess the ability of a model to detect truly related word pairs, as well as to perform in-depth analyses of the types of semantic relations that a model favors. We discuss the motivations for BLESS, describe its construction and structure, and present examples of its usage in the evaluation of distributional semantic models. </abstract>
	<introduction> In NLP, it is customary to distinguish between intrinsic evaluations , testing a system in itself, andextrinsic evaluations , measuring its performance insome task or application (Sparck Jones and Galliers,1996). For instance, the intrinsic evaluation of a dependency parser will measure its accuracy in identifying speciﬁc syntactic relations, while its extrinsicevaluation will focus on the impact of the parser ontasks such as question answering or machine translation. Current approaches to the evaluation of Distributional Semantic Models (DSMs, also knownas semantic spaces, vector-space models, etc.; seeTurney and Pantel (2010) for a survey) are taskoriented. Model performance is evaluated in “semantic tasks”, such as detecting synonyms, recognizing analogies, modeling verb selectional preferences, ranking paraphrases, etc. Measuring the performance of DSMs on such tasks represents an in-direct test of their ability to capture lexical meaning. The task-oriented benchmarks adopted in distributional semantics have not speciﬁcally been designed to evaluate DSMs. For instance, the widelyused TOEFL synonym detection task was designedto test the learners’ proﬁciency in English as a second language, and not to investigate the structure oftheir semantic representations (cf. Section 2).To gain a real insight into the abilities of DSMs toaddress lexical semantics, existing benchmarks mustbe complemented with a more intrinsically orientedapproach, to perform direct tests on the speciﬁc aspects of lexical knowledge captured by the models.In order to achieve this goal, three conditions mustbe met: (i) to single out the particular aspects ofmeaning that we want to focus on in the evaluationof DSMs; (ii) to design a data set that is able to explicitly and reliably encode the target semantic information; (iii) to specify the evaluation criteria of thesystem performance on the data set, in order to getan estimate of the intrinsic ability of DSMs to copewith the selected semantic aspects. In this paper, weaddress these three conditions by presenting BLESS(Baroni and Lenci Evaluation of Semantic Spaces),a new data set speciﬁcally geared towards the intrinsic evaluation of DSMs, downloadable from:http://clic.cimec.unitn.it/distsem . </introduction>
	<discussion> why we allow models to pick their favorite from aset of relata instantiating the same relation). In thisway, for each of the 200 BLESS concepts, we obtain </discussion>
	<conclusion>  </conclusion>
	<biblio>  </biblio>
</article>
