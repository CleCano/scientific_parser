<article>
	<preamble>kesslerMETICS-ICDIM2019.pdf</preamble>
	<titre>A word embedding approach to explore a collection of discussions of people in psychological distress</titre>
	<auteurs>
		<auteur>
			<nom>Rémy Kessler</nom>
			<mail>remy.kessler@univ-ubs.fr</mail>
			<affiliation></affiliation>
		</auteur>
	</auteurs>
	<abstract> In order to better adapt to society, an association has developed a web chat application that allows anyone to express and share their concerns and anguishes. Several thousand anonymous conversations have been gathered and form a new corpus of stories about human distress and social violence. We present a method of corpus analysis combining unsupervised learning and word embedding in order to bring out the themes of this particular collection. We compare this approach with a standard algorithm of the literature on a labeled corpus and obtain very good results. An interpretation of the obtained clusters collection conﬁrms the interest of the method. Keywords —word2vec, unsupervised learning, word embedding. </abstract>
	<introduction>  </introduction>
	<discussion> 1stRémy KesslerUniversité Bretagne SudCNRS 6074A56017 Vannes,Franceremy.kessler@univ-ubs.fr2ndNicolas BéchetUniversité Bretagne SudCNRS 6074A56017 Vannes,Francenicolas.bechet@irisa.fr3rdGudrun LedegenUniversité Rennes IIPREFics, EA 42465043 Rennes, Francegudrun.ledegen@univ-rennes2.fr4rdFrederic Pugnière-SaavedraUniversité Bretagne SudPREFics, EA 424656017 Vannes, Francefrederic.pugniere-saavedra@univ-ubs.frAbstract —In order to better adapt to society, an associationhas developed a web chat application that allows anyone toexpress and share their concerns and anguishes. Several thousandanonymous conversations have been gathered and form a newcorpus of stories about human distress and social violence. Wepresent a method of corpus analysis combining unsupervisedlearning and word embedding in order to bring out the themesof this particular collection. We compare this approach with astandard algorithm of the literature on a labeled corpus andobtain very good results. An interpretation of the obtainedclusters collection conﬁrms the interest of the method.Keywords —word2vec, unsupervised learning, word embedding.I. I NTRODUCTIONSince the nineties, social suffering has been a theme that hasreceived much attention from public and associative action.Among the consequences, there is an explosion of listeningplaces or socio-technical devices of communication whoseobjectives consist in moderating the various forms of sufferingby the liberation of the speech for a therapeutic purpose [1][2]. As part of the METICS project, a suicide preventionassociation developed an application of web chat to meetthis need. The web chat is an area that allows anyone toexpress and share with a volunteer listener their concerns andanguishes. The main speciﬁcity of this device is its anonymousnature. Protected by a pseudonym, the writers are invitedto discuss with a volunteer the problematic aspects of theirexistence. Several thousand anonymous conversations havebeen gathered and form a corpus of unpublished stories abouthuman distress. The purpose of the METICS project is to makevisible the ordinary forms of suffering usually removed fromcommon spaces and to grasp both its modes of enunciation anddigital support. In this study, we want to automatically identifythe reason for coming on the web chat for each participant.Indeed, even if the association provided us with the themeof all the conversations (work, loneliness, violence, racism,addictions, family, etc.), the original reason has not beenpreserved. In what follows, we ﬁrst review some of the relatedwork in Section II. Section III presents the resources used andgives some statistics about the collection. An overview of thesystem and the strategy for identify the reason for comingon the web chat is given in Section IV. Section V presentsthe experimental protocol, an evaluation of our system and aninterpretation of the ﬁnal results on the collection of humandistress.II. R ELATED WORKSThe main characteristic of the approach presented in thispaper is to only have to provide the labels of the classes tobe predicted. This method does not need to have a taggeddata set to predict the different classes, so it is closer to anunsupervised (clustering) or semi-supervised learning methodthan a supervised. The main idea of clustering is to groupuntagged data into a number of clusters, such that similar examples are grouped together and different ones are separated.In clustering, the number of classes and the distribution ofinstances between classes are unknown and the goal is to ﬁndmeaningful clusters.One kind of clustering methods is the partitioning-basedone. The k-means algorithm [3] is one of the most popular partitioning-based algorithms because it provides a goodcompromise between the quality of the solution obtained andits computational complexity [4]. K-means aims to ﬁnd kcentroids, one for each cluster, minimizing the sum of thedistances of each instance of data from its respective centroid.We can cite other partitioning-based algorithms such as kmedoids or PAM (Partition Around Medoids), which is anevolution of k-means [5]. Hierarchical approaches produceclusters by recursively partitioning data backwards or upwards.For example, in a hierarchical ascending classiﬁcation orCAH [6], each example from the initial dataset represents acluster. Then, the clusters are merged, according to a similaritymeasure, until the desired tree structure is obtained. The resultof this clustering method is called a dendrogram. Densitybased methods like the EM algorithm [7] assume that the databelonging to each cluster is derived from a speciﬁc probabilitydistribution [8]. The idea is to grow a cluster as the density inthe neighborhood of the cluster exceeds a predeﬁned threshold.Model-based classiﬁcation methods like self-organizingmap - SOM [9] are focus on ﬁnding features to represent eachcluster. The most used methods are decision trees and neuralnetworks. Approaches based on semi-supervised learning suchas label propagation algorithm [10] are similar to the methodproposed in this paper because they consist in using a learningdataset consisting of a few labelled data points to build amodel for labelling a larger number of unlabelled data. Closerto the theme of our collection, [11] and [12] use supervisedapproaches to automatically detect suicidal people in socialnetworks. They extract speciﬁc features like word distributionstatistics or sentiments to train different machine-learning classiﬁers and compare performance of machine-learning modelsagainst the judgments of psychiatric trainees and mental healthprofessionals. More recently, CLEF challenge in 2018 consistsof performing a task on early risk detection of depression ontexts written in Social Media1. However, these papers and thistask involve tagged data sets, which is the main differencewith our proposed approach (we do not have tagged data set).III. R ESOURCES AND STATISTICSThe association provided a collection of conversations between volunteers and callers between 2005 and 2015, whichis called “METICS collection” henceforth.To reduce noise in the collection, we removed all thediscussions containing fewer than 15 exchanges between acaller and a person from the association, these exchanges aregenerally unrepresentative (connection problem, request forinformation, etc.). We observe particular linguistic phenomenalike emoticons2, acronyms, mistakes (spelling, typography,glued words) and an explosive lexical creativity [13]. Thesephenomena have their origin in the mode of communication(direct or semi-direct), the speed of the composition of themessage or in the technological constraints of input imposedby the material (mobile terminal, tablet, etc.). In addition, weused a subset of the collection of the French newspaper, LeMonde to validate our method on a tagged corpus. We onlykeep articles on television, politics, art, science or economics.Figure 1 presents some descriptive statistics of these twocollections.IV. M ETHODOLOGYA. System OverviewFigure 2 presents an overview of the system, each step willbe detailed in the rest of the section. In the ﬁrst step (module¬), we apply different linguistic pre-processing to eachdiscussion. The next module ( ­) creates a word embeddingmodel with these discussions while the third module ( ®) usesthis model to create speciﬁc vectors. The last module ( ¯)performs a prediction for each discussion before separatingthe collection into clusters based on the predicted class.1http://early.irlab.org/2Symbols used in written messages to express emotions, e.g. smile orsadnessCollection METICS Le-MondeTotal number of documents 17 594 205 661Without pre-processingTotal number of words 12 276 973 87 122 002Total number of different words 158 361 419 579Average words/document 698 424With pre-processingTotal number of words 4 529 793 41 425 938Total number of different words 120 684 419 006Average words/document 257 201Fig. 1. Statistics of both collections. </discussion>
	<conclusion>  </conclusion>
	<biblio>  </biblio>
</article>
