<article>
	<preamble>surveyTermExtraction.pdf</preamble>
	<titre>AUTOMATIC TERM DETECTION: A REVIEW OF CURRENT SYSTEMS</titre>
	<auteurs>
	</auteurs>
	<abstract> In this paper we account for the main  characteristics and performance of a  number of recently developed term extraction systems. The analysed tools  represent the main strategies followed by  researchers in this area. All systems  are analysed and compared against a set of technically relevant characteristics. </abstract>
	<introduction>In the late 80s there was an acute need , from different disciplines and goals, to automatically extract terminological units from specialised texts. In the 90s large computerised textual corpora have been constructed resulting in the first programs for terminology extraction1 (henceforth TE) which have showed encouraging results. Throughout the current decade computa tional linguists, applied linguists, translators, interpreters, scientific journalists and computer engineers have been interested in automatically isolating terminology from texts. There are many goals that have led these different profe ssional groups to design software tools so as to directly extract terminology from texts: building of glossaries, vocabularies and terminological dictionaries; text indexing; automatic translation; building of                                                            * In Bourigault, D.; Jacquemin, C.; L’Homme, M-C. (2001) Recent Advances in Computational Terminology , 53-88. 1 In order to give a broa der view of TE we use both extractor  and detector  to refer to the same notion. However, we are aware of the fact that some schol ars attribute different meanings to these words. 2 Aut omatic Term Detection: a Review of C urrent  Systems knowledge databases; construction of hype rtext systems; construction of expert systems and corpus analysis.  From the appearance of TERMINO (the first broadly known term detector) in 1990 until today a number of projects to design different types of automatic terminology detectors have been carried out to assist terminological work. However, despite the large number of studies in progress, the automatisation of the terminological extraction phase is still fraught with problems. The main problems encountered by term extractors are: (1) identification of complex terms, that is, determining where a terminological phrase begins and ends; (2) recognition of complex terms, that is, deciding whether a discursive unit constitutes a terminological phrase or a free unit; (3) identification of the terminological nature of a lexical unit, that is, knowing whether in a specialised text a lexical unit has a terminological na ture or belongs to general language and (4) appropriateness of a terminological unit to a given vocabulary (this has scarcely been addressed from the point of view of automatization).  Systems for TE are based on three types of knowledge: (a) linguistic; (b) statistical; (c) hybrid (statistical and linguistic). Hence, there are different approaches to automatic term detecti on. All systems analyse a corpus of specialised texts in electronic form and extract lists of word chunks (i.e. candidate terms) that are to be confirmed by the terminologist. To make the terminologist’s task easier the candidate term is provided with its context and, when available, with any other furt her information (freque ncy, relationship between terms, etc.) Two relevant aspects regarding the nature of terms are termhood and unithood2; TE systems may be designed based on only one of these two aspects. Some practical experiments following each scheme for ranking a set terms extracted from Japanese texts are presented in (Nakagawa&amp;amp;amp;amp; Mori, 1998). They show that results in precision and recall are very close but the set of terms extracted are a somewhat different. This is still a research issue. Alongside term detection we find the task of automatic document indexing (i.e. information retrieval, IR). This applied field of natural language processing (NLP) techniques has an interesting common point with automatic term detection, that is, word chunks that index a given document are often terminological units. This same goal explains why many extraction systems are rooted on IR as well as on the analys is of a specific IR system with no application whatsoever to TE.                                                            </introduction>
	<discussion></discussion>
	<conclusion>We can reach some conclusions after havi ng analysed and evaluated some of the main systems of TE designed in the last decade:                                                            11 The system has been intensively te sted with regard to the indexing frequency, but not in relation to the quality of the extracted terms. 28 Aut omatic Term Detection: a Review of C urrent  Systems a) The efficiency of the extraction presen ts a high degree of variation from one to another. Broadly speaking, there is neither clear nor measurable explanation of the final results. Besides, we have to b ear in mind that these systems are tested with small and highly specialised corpora. This lack of data makes it difficult to evaluate and compare them. However, it does not prevent pinpointing those solutions, which are considered va lid to solve specific problems. b) None of the systems is entirely satisfactory due to two main reasons. First, all systems produce too much silence, especially statistically-based systems. Second, all of them generate a great deal of noise, especially linguistically-based systems. c) Taking into account the noise generated, all systems propose large lists of candidate terms, which at the end of the process have to be manually accepted or rejected. d) Most of the TE systems are related to only one language: French or English. Usually the language specific data is embedded in the tool. This makes difficult to use the system in a language other than the original. e) As has been already pointed out, traini ng corpora tend to be small (from 2.3 to 12 Kwords) and highly specialised with regard to the topic as well as the specialisation degree. This allows for a quite precise patterns and lexicosemantic, formal and morphosyntactic heuristics albeit this only applies to highly specialised corpora. f) All systems focus entirely on NPs and none of them deals with verbal phrases. This is because there is a high rate of terminological NPs in specialised texts. This rate can vary according to the topi c and the specialisation degree. Despite what has just been noted, it is noteworthy that all specialised languages have their own verbs (or specific combinations of a verbal nature), no matter how low the ratio is in comparison with nouns. g) As a result, none of the systems refers to the distinction between nominal collocations and nominal terminological units of a syntactic nature. Nor do they refer to phraseology. h) Many of the systems make use of a number of morphosyntactic patterns to identify complex terms. However they account for most of the terminological units they are still too few and also not very constraining. Thus, for English are AN and NN, for French NA and N prep N.  Some terms present structures other than these ones and they are never det ected. Those systems based only on these types of linguistic techniques generate too much noise. i) It is generally agreed that frequency is a good criterion to indicate that a candidate term is actually a terminological unit. However, frequency is not on its own a sufficient criterion, as it yields a great deal of noise. j) Only a few recent systems use semantic  information to recognise and delimit terminological units although its use takes place at different levels. AUT OMA TIC TERM DETECTION: A REVIEW  OF CURRENT  SYSTEMS  </conclusion>
	<biblio>  Arppe, A. 1995. “Term extraction from unrestricted text”. Lingsoft Web Site:  http://www.lingsoft.com   Ahmad, K., Davies, A., Fulford, H. and Rogers, M. 1992. “What is a term? The  semiautomatic extraction of terms from text”. Translation Studies – an  interdiscipline. Amsterdam: John Benjamins.  Bourigault, D. 1994. LEXTER, un Logiciel d'EXtraction de TERminologie.  Application à l'acquisition des connaissances à partir de textes. PhD Thesis.  Paris: École des Hautes Ét udes en Sciences Sociales.  Bourigault, D., Gonzalez- Mullier, I. and Gros, C. 1996. “LEXTER, a Natural  Language Processing Tool for Terminology Extraction”. Proceedings of the  7th EURALEX International Congress. Göteborg.  Brown, P. F., Cocke, F., Pietra, S., Felihek. F., Merces, R. and Rossin, P. (1988)  A statistical approach to language translation. Procedings of 12th International  Conference of Computational Linguistic (Coling-88).  Budapest, Hungary.   Cabré, M.T. 1999. Terminology. Theory, methods and applications.  Amsterdam:  John Benjamins.  Church, K. 1989. “Word association norms, mutual information and  lexicography”. Proceedings of the 27th annual meeting of the ACL. Vancouver,  76-83.  Condamines, A. 1995. “Terminology: new needs, new perspectives”.  Terminology, 2, 2: 219-238.  Dagan, I. and Church, K. 1994. “Termight: Identifying and translating technical  terminology”. Proceedings of the Fourth Conference on Applied Natural  Language Processing, 34-40.  Daille, B. 1994. Approche mixte pour l'extraction de terminologie: statistique  lexicale et filtres linguistiques . PhD dissertation. Paris: Université Paris VII.   Daille, B. and Jacquemin, C 1998. “Lexi cal database and information access: a  fruitfull association?”. First International Conference on LREC.  Granada.  AUT OMA TIC TERM DETECTION: A REVIEW  OF CURRENT  SYSTEMS   31    David, S. and Plante, P. 1991. “Le progi ciel TERMINO: de la nécessité d'une  analyse morphosyntaxique pour le dépou illement terminologique des textes”.  Proceedings of the Montreal Coll oquium Les industries de la langue:  perspectives des années 1990,  1: 71-88.  Enguehard, C. and Pantera, L. 1994. “Automatic Natural Acquisition of a  Terminology”. Journal of Quantitative Linguistics,  2, 1: 27-32.  Estopà, R. 1999. Extracció de terminologia: elements per a la construcció d’un  SEACUSE (Sistema d’extracció automàtica de candidats a unitats de  significació especialitzada).  PhD thesis, Barcelona: Universitat Pompeu Fabra.  Estopà, R. and Vivaldi, J. 1998. “Systèmes de détection automatique de  (candidats à) termes: vers  une proposition intégratrice”. Actes des 7èmes  Journées ERLA-GLAT, Brest , 385-410  Evans, D.A. and Zhai, C. 1996. “Noun-phrase Analysis in Unrestricted Text for  information retrieval”. Proceedings of ACL, Sant a Cruz, University of  California,  17-24.  Frantzi, K. and Ananiadou, S. 1995. Statistical measures for terminological  extraction. Working paper of the Department of Computing of Manchester  Metropolitan University.   Frantzi, K. T. 1997. “Incorporating context information for extraction of terms”.  Proceedings  of ACL/EACL, Madrid, 501-503.  Habert, B., Naulleau, E.  and Nazarenko, A. 1996.  “Symbolic word clustering for  medium-size corpora”. Proceedings of Coling’96 : 490-495.  Heid, U., Jauss, S., Krüger, K. and Hohmann, A. 1996. “Term extraction with  standard tools for corpus exploration. Experience from German”. In: TKE ‘96:  Terminology and Knowledge Engineering,, 139-150. Berlin: Indeks Verlag.    Jacquemin, C. 1994. “Recycling Terms into a Partial Parser”. Proceedings of   ANLP’94 , 113-118.  Jacquemin, C. 1999. “Syntagmatic and paradigmatic representations of term  variation”. Proceedings of  ACL'99, University of Maryland, 341-348.  Jacquin, C. and Liscouet, M. 1996. “Terminology extraction from texts corpora:  application to document keeping via Internet”. In: TKE ‘96: Terminology and  Knowledge Engineering, 74-83.  Berlin: Indeks Verlag.  Justeson, J. and Katz, S. 1995. “Technical terminology: some linguistic  properties and an algorithm for identification in text”. Natural Language  Engineering,  1, 1: 9-27.  Kageura, K. and Umino, B. 1996. “Met hods of Automatic Term Recognition”.  Papers of the  National Center for Science Information Systems , 1-22. 32 Aut omatic Term Detection: a Review of C urrent  Systems  Kageura, K., Yoshioka, M., Koyama, T. and Nozue, T. 1998. “Towards a  common testbed for corpus-based computational terminology”. Proceedings of  Computerm ‘98, Montreal, 81-85.  Karlsson, F. 1990. “Constraint grammar as a framework for parsing running  text”. Proceedings of the  13th International conference on computational  linguistic , 3: 168-173.  Lauriston, A. 1994. “Automatic recogniti on of complex terms: Problems and the  TERMINO solution”. Terminology , 1, 1: 147-170.  Maynard, D. and Ananiadou, S. 1999. “Identifying contextual information for  multi-word term extraction”. In: TKE ‘99: Terminology and Knowledge  Engineering, 212-221. Vienna: TermNet.   Nakagawa, H. and Mori , T. 1998. “N ested collocation and Compound Noun for  Term Extraction”. Proceedings of Computerm ’98,  Montreal, 64-70.  Naulleau, E 1998. Apprentissage et filtrage syntaxico-sémantique de syntagmes  nominaux pertinents pour la recherche documentaire.  PhD thesis. Paris:  Université Paris 13.  Naulleau, E. 1999. “Profile-guided terminology extraction”. In: TKE‘99:  Terminology and Knowledge Engineering . 222-240. Vienna: TermNet.   Plante, P. and Dumas, L. 1998. “Le Dépoulliment terminologique assisté par  ordinateur”. Terminogramme , 46, 24-28.  Shieber, S.N. 1986. “An Introduction to Unification-Based Approaches to  grammar ”. CSLI Lecture Notes of  University Press, 4.  Smadja, F. 1991.  Extracting collocations from text. An application : language  generation . Columbia: Columbia University. Department of Computer  Science. [Unpublished doctoral dissertation ]  Voutilainen, A. 1993. “NPtool, a de tector of English noun phrases”. Proceedings  of the  Workshop on Very Large Corpora.   Zhai, C., Tong, X., Milic-Frayling, N. and Evans, D.A. 1996. “Evaluation of  syntactic phrase indexing CLARIT. NLP track report”. Proceedings of the  TREC-5.  TREC Web Site:  http://trec.nist.gov/pubs /trec5/t5_proceedings.html </biblio>
</article>